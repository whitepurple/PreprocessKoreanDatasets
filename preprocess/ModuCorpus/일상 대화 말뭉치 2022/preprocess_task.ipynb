{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train: 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]\n",
                        "valid: 0it [00:00, ?it/s]\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import json\n",
                "import re\n",
                "from tqdm import tqdm\n",
                "\n",
                "settings = json.loads(Path('../../../settings.json').read_text())",
                "preprocessed_data_path = Path(settings['preprocessed_data_path'])",
                "data_path = Path('.').resolve()",
                "data_name = data_path.name",
                "source_name = data_path.parent.name",
                "preprocessed_dir = preprocessed_data_path/source_name/data_name",

                "source_data_dir = preprocessed_dir/'preprocessed'\n",
                "splits = ['train', 'valid']\n",
                "tasks = ['LM(한국어)', '대화 주제 식별', '화자 관계 식별', 'dialog', '화자 인식']\n",
                "task_data_dir = preprocessed_dir/'preprocessed_task'\n",
                "task_data_dir.mkdir(exist_ok=True)\n",
                "for task in tasks:\n",
                "    task_path = task_data_dir/task\n",
                "    task_path.mkdir(exist_ok=True)\n",
                "    \n",
                "#### prepare for task preprocess\n",
                "pattern = re.compile(r'\\s+')\n",
                "#### prepare for task preprocess end\n",
                "\n",
                "#### task preprocess\n",
                "for split in splits:\n",
                "    source_data_dir_split = source_data_dir/split\n",
                "    task_files = [(task_data_dir/task/f'{split}.jsonl').open('w', encoding='utf-8') for task in tasks]\n",
                "    for source_data in tqdm(list(source_data_dir_split.iterdir()), desc=split):\n",
                "        source_data = source_data.open()\n",
                "        for line in source_data.readlines():\n",
                "            line = json.loads(line)\n",
                "            \n",
                "            #### data preprocess\n",
                "            #### ! utterance 합치기\n",
                "            #### ! speaker_id가 변경되는 것을 기준으로 utterence를 합침\n",
                "\n",
                "            new_utt = {\"utterence\": []}\n",
                "            new_utt_id_prefix = line['id']+'.1.'\n",
                "            utt_idx = 1\n",
                "            for utt in line['utterance']:\n",
                "                if new_utt['utterence'] == [] or new_utt['utterence'][-1]['speaker_id'] != utt['speaker_id']:\n",
                "                    new_utt['utterence'].append({   'id': new_utt_id_prefix+str(utt_idx),\n",
                "                                                    'start_id': utt['id'],\n",
                "                                                    'end_id': utt['id'],\n",
                "                                                    'speaker_id': utt['speaker_id'],\n",
                "                                                    'form': utt['form'],\n",
                "                                                    'original_form': utt['original_form']})\n",
                "                    utt_idx += 1\n",
                "                else:\n",
                "                    new_utt['utterence'][-1]['original_form'] += ' ' + utt['original_form']\n",
                "                    new_utt['utterence'][-1]['form'] += ' ' + utt['form']\n",
                "                    new_utt['utterence'][-1]['end_id'] = utt['id']\n",
                "            \n",
                "            based_text = {'original_form':[utt['original_form'].replace('  ', ' ').strip() for utt in new_utt['utterence']],\n",
                "                            'form':[utt['form'].replace('  ', ' ').strip() for utt in new_utt['utterence']],}\n",
                "            \n",
                "            \n",
                "            #### data preprocess end \n",
                "\n",
                "            #### LM(한국어)\n",
                "            data = {'text': None}\n",
                "            ## preprocess data from line\n",
                "            data['text'] = '\\n'.join(based_text['form'])\n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[0].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### LM(한국어) end\n",
                "\n",
                "\n",
                "            #### 대화 주제 식별\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            data['input'] = based_text\n",
                "            data['output'] = line['metadata']['topic']\n",
                "            ## preprocess data from line end\n",
                "            task_files[1].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 대화 주제 식별 end\n",
                "\n",
                "\n",
                "            #### 화자 관계 식별\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            data['input'] = {'speaker': line['metadata']['speaker'],\n",
                "                             'dialog': new_utt['utterence']}\n",
                "            data['output'] = line['metadata']['setting']['relation']\n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[2].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 화자 관계 식별 end\n",
                "\n",
                "\n",
                "            #### dialog\n",
                "            data = {'text': None}\n",
                "            ## preprocess data from line\n",
                "            data['text'] = {'metadata' : line['metadata']}\n",
                "            data['text']['speaker'] = line['metadata']['speaker']\n",
                "            data['text']['utterence'] = based_text\n",
                "            data['text']['dialog'] = [utt['speaker_id'] for utt in new_utt['utterence']]        \n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[3].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### dialog end\n",
                "\n",
                "\n",
                "            #### 화자 인식\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            data['input'] = {'metadata' : line['metadata']}\n",
                "            data['input']['speaker'] = line['metadata']['speaker']\n",
                "            data['input']['utterence'] = [{'id':utt['id'],'original_form':utt['original_form']} for utt in line['utterance']]\n",
                "            data['output'] = [utt['speaker_id'] for utt in line['utterance']]        \n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[4].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 화자 인식 end\n",
                "\n",
                "\n",
                "            \n",
                "    #         break\n",
                "    #     break\n",
                "    # break\n",
                "\n",
                "    for path in task_files:\n",
                "        path.close()      \n",
                "        \n",
                "#### task preprocess end      "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
