{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train: 100%|██████████| 1/1 [04:58<00:00, 298.33s/it]\n",
                        "valid: 100%|██████████| 1/1 [00:35<00:00, 35.59s/it]\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import json\n",
                "import re\n",
                "from tqdm import tqdm\n",
                "\n",
                "\n",
                "settings = json.loads(Path('../../../settings.json').read_text())",
                "preprocessed_data_path = Path(settings['preprocessed_data_path'])",
                "data_path = Path('.').resolve()",
                "data_name = data_path.name",
                "source_name = data_path.parent.name",
                "preprocessed_dir = preprocessed_data_path/source_name/data_name",

                "source_data_dir = preprocessed_dir/'preprocessed'\n",
                "splits = ['train', 'valid']\n",
                "tasks = ['단어별 방언 식별', '방언 종류 예측', '대화 주제 식별', '화자 인식', '화자 관계 식별', 'LM(한국어)', 'dialog', '번역(방언-표준어)', '번역(표준어-방언)']\n",
                "task_data_dir = preprocessed_dir/'preprocessed_task'\n",
                "task_data_dir.mkdir(exist_ok=True)\n",
                "for task in tasks:\n",
                "    task_path = task_data_dir/task\n",
                "    task_path.mkdir(exist_ok=True)\n",
                "    \n",
                "#### prepare for task preprocess\n",
                "def remove_nested_brackets(text):\n",
                "\n",
                "    # 중괄호, 소괄호, 대괄호 모두를 제거하기 위한 패턴\n",
                "    brackets_pattern = re.compile(r'\\{[^{}]*\\}|\\([^()]*\\)|\\[[^\\[\\]]*\\]')\n",
                "\n",
                "    # &로 둘러싸인 단어 제거 패턴 추가\n",
                "    special_words_pattern = re.compile(r'&[^&]*&')\n",
                "\n",
                "    while True:\n",
                "        new_text = brackets_pattern.sub('', text)\n",
                "        if new_text == text:  # 변경 사항이 없으면 반복 중단\n",
                "            break\n",
                "        text = new_text\n",
                "\n",
                "    text = special_words_pattern.sub('', text)\n",
                "\n",
                "    return text\n",
                "\n",
                "#### prepare for task preprocess end\n",
                "\n",
                "#### task preprocess\n",
                "for split in splits:\n",
                "    source_data_dir_split = source_data_dir/split\n",
                "    task_files = [(task_data_dir/task/f'{split}.jsonl').open('w', encoding='utf-8') for task in tasks]\n",
                "    for source_data in tqdm(list(source_data_dir_split.iterdir()), desc=split):\n",
                "        source_data = source_data.open()\n",
                "        for line in source_data.readlines():\n",
                "            line = json.loads(line)\n",
                "\n",
                "            #### data preproces\n",
                "\n",
                "            filtered_utterances = []\n",
                "            for utt in line['utterance']:\n",
                "                fields = ['standard_form', 'dialect_form']\n",
                "                for field in fields:\n",
                "                    if field in utt:\n",
                "\n",
                "                        cleaned_text = remove_nested_brackets(utt[field])\n",
                "\n",
                "                        utt[field] = cleaned_text\n",
                "                filtered_utterances.append(utt)\n",
                "\n",
                "            line['utterance'] = filtered_utterances\n",
                "\n",
                "            #### data preprocess end \n",
                "\n",
                "            #### 단어별 방언 식별\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            in1=[]\n",
                "            ou1=[]\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'id': utterance['id'],\n",
                "                    'standard_form': utterance['standard_form'],\n",
                "                    'eojeolList': [{'id': eojeol['id'], 'eojeol': eojeol['eojeol']} for eojeol in utterance['eojeolList']]\n",
                "                }\n",
                "                in1.append(result)\n",
                "\n",
                "            for utterance in line['utterance']:\n",
                "                eojeol_list = {\n",
                "                        'id': utterance['id'],\n",
                "                        'eojeolList': [{'standard': eojeol['standard'], 'isDialect': eojeol['isDialect']} for eojeol in utterance['eojeolList']]\n",
                "                    }\n",
                "                ou1.append(eojeol_list)\n",
                "            \n",
                "            data['input']=in1\n",
                "            data['output']=ou1\n",
                "            ## preprocess data from line end\n",
                "            task_files[0].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 단어별 방언 식별 end\n",
                "\n",
                "\n",
                "            #### 방언 종류 예측\n",
                "            data = {'input': None, 'output': None}\n",
                "            in2=[]\n",
                "            ou2=[]\n",
                "            ## preprocess data from line\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'id': utterance['id'],\n",
                "                    'dialect_form': utterance['dialect_form'],\n",
                "                    'eojeolList': [{'id': eojeol['id'], 'eojeol': eojeol['eojeol']} for eojeol in utterance['eojeolList']]\n",
                "                }\n",
                "                in2.append(result)\n",
                "                ou2.append(any([eo['isDialect'] for eo in utterance['eojeolList']]))\n",
                "\n",
                "            data['input'] = in2\n",
                "\n",
                "            dialect = line['metadata']['category'].split('>')[0].strip()\n",
                "            data['output'] = ou2\n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[1].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 방언 종류 예측 end\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "            #### 대화 주제 식별\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            \n",
                "            in3=[]\n",
                "            topic = line['metadata']['topic']\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'standard_form': utterance['standard_form'],\n",
                "                }\n",
                "                in3.append(result)\n",
                "                ## preprocess data from line end\n",
                "\n",
                "            data['input']=in3\n",
                "            data['output']=topic\n",
                "\n",
                "            task_files[2].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "                #### 대화 주제 식별 end\n",
                "\n",
                "\n",
                "\n",
                "            #### 화자 인식\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "\n",
                "            in4 = []\n",
                "            ou4 = []\n",
                "            speakers = {speaker['id']: speaker for speaker in line['speaker']}\n",
                "            \n",
                "            for utterance in line['utterance']:\n",
                "                speaker_id = utterance['speaker_id']\n",
                "                speaker_info = speakers.get(speaker_id, {})\n",
                "\n",
                "                result = {\n",
                "                    'age': speaker_info.get('age', 'Unknown'),\n",
                "                    'occupation': speaker_info.get('occupation', 'Unknown'),\n",
                "                    'sex': speaker_info.get('sex', 'Unknown'),\n",
                "                    'birthplace': speaker_info.get('birthplace', 'Unknown'),\n",
                "                    'principal_residence': speaker_info.get('principal_residence', 'Unknown'),\n",
                "                    'current_residence': speaker_info.get('current_residence', 'Unknown'),\n",
                "                    'education': speaker_info.get('education', 'Unknown')\n",
                "                }\n",
                "                in4.append(result)\n",
                "                \n",
                "            for utterance in line['utterance']:\n",
                "                speaker_id = utterance['speaker_id']\n",
                "                speaker_info = speakers.get(speaker_id, {})\n",
                "\n",
                "                result = speaker_id\n",
                "                ou4.append(result)\n",
                "\n",
                "\n",
                "            data['input']=in4\n",
                "            data['output']=ou4\n",
                "            ## preprocess data from line end\n",
                "            task_files[3].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 화자 인식 end\n",
                "\n",
                "\n",
                "\n",
                "            #### 화자 관계 식별\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            in5=[]\n",
                "            ou5=[]\n",
                "            speakers = {speaker['id']: speaker for speaker in line['speaker']}\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'id': utterance['id'],\n",
                "                    'standard_form': utterance['standard_form'],\n",
                "                    'speaker_id': utterance['speaker_id'] \n",
                "                }\n",
                "                \n",
                "\n",
                "                speaker_id = utterance['speaker_id']\n",
                "                speaker_info = speakers.get(speaker_id, {})\n",
                "\n",
                "                result['speaker_id'] = speaker_id\n",
                "                result['speaker_age'] = speaker_info.get('age', 'Unknown')\n",
                "                result['speaker_occupation'] = speaker_info.get('occupation', 'Unknown')\n",
                "                result['speaker_sex'] = speaker_info.get('sex', 'Unknown')\n",
                "\n",
                "                in5.append(result)\n",
                "\n",
                "\n",
                "            if 'setting' in line:\n",
                "                setting_relation = line['setting'].get('relation')\n",
                "                result = {\n",
                "                    'relation': setting_relation\n",
                "                }\n",
                "\n",
                "                ou5.append(result)\n",
                "\n",
                "            data['input']=in5\n",
                "            data['output']=ou5\n",
                "            ## preprocess data from line end\n",
                "            task_files[4].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 화자 관계 식별 end\n",
                "\n",
                "\n",
                "            #### LM(한국어)\n",
                "            data = {'text': None}\n",
                "            ## preprocess data from line\n",
                "\n",
                "            in6 = []\n",
                "            for utterance in line['utterance']:\n",
                "                result = utterance['dialect_form']\n",
                "                in6.append(result)\n",
                "\n",
                "            text1 = '\\n'.join(in6)\n",
                "\n",
                "            data['text'] = text1\n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[5].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### LM(한국어) end\n",
                "\n",
                "\n",
                "            #### dialog\n",
                "            data = {'text': None}\n",
                "            ## preprocess data from line\n",
                "            \n",
                "            data['text'] = {}\n",
                "            data['text']['metadata'] = line['metadata']\n",
                "            data['text']['speaker'] = line['speaker']\n",
                "            data['text']['dialog'] = []  # 새로운 dialog 리스트를 추가\n",
                "\n",
                "            for utt in line['utterance']:\n",
                "                # speaker_id와 form만 포함하는 새로운 딕셔너리 생성\n",
                "                new_utt = {'speaker_id': utt['speaker_id'], 'dialect_form': utt['dialect_form']}\n",
                "                data['text']['dialog'].append(new_utt)\n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[6].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### dialog end\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "            #### 번역(방언-표준어)\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "\n",
                "            in7 = []\n",
                "            ou7 = []\n",
                "            \n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'dialect_form': utterance['dialect_form']\n",
                "                }\n",
                "                in7.append(result)\n",
                "                \n",
                "\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'standard_form': utterance['standard_form']\n",
                "                }\n",
                "                ou7.append(result)\n",
                "            data['input']=in7\n",
                "            data['output']=ou7\n",
                "            ## preprocess data from line end\n",
                "            task_files[7].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 번역(방언-표준어) end\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "            #### 번역(표준어-방언)\n",
                "            data = {'input': None, 'output': None}\n",
                "            ## preprocess data from line\n",
                "            in8 = []\n",
                "            ou8 = []\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'standard_form': utterance['standard_form']\n",
                "                }\n",
                "                in8.append(result)\n",
                "                \n",
                "\n",
                "            for utterance in line['utterance']:\n",
                "                result = {\n",
                "                    'dialect_form': utterance['dialect_form']\n",
                "                }\n",
                "                ou8.append(result)\n",
                "            data['input']=in8\n",
                "            data['output']=ou8\n",
                "\n",
                "            ## preprocess data from line end\n",
                "            task_files[8].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 번역(표준어-방언) end\n",
                "\n",
                "\n",
                "    #         break\n",
                "    #     break\n",
                "    # break\n",
                "\n",
                "    for path in task_files:\n",
                "        path.close()      \n",
                "        \n",
                "#### task preprocess end      "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
