{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train: 100%|██████████| 21/21 [00:17<00:00,  1.22it/s]\n",
                        "valid: 100%|██████████| 21/21 [00:01<00:00, 15.55it/s]\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import json\n",
                "import re\n",
                "from tqdm import tqdm\n",
                "\n",
                "settings = json.loads(Path('../../../settings.json').read_text())",
                "preprocessed_data_path = Path(settings['preprocessed_data_path'])",
                "data_path = Path('.').resolve()",
                "data_name = data_path.name",
                "source_name = data_path.parent.name",
                "preprocessed_dir = preprocessed_data_path/source_name/data_name",

                "source_data_dir = preprocessed_dir/'preprocessed'\n",
                "splits = ['train', 'valid']\n",
                "tasks = ['LM(한국어)', 'LM(영어)', '번역(한-영)', '번역(한-러)', '번역(한-스)', '다국어 번역 교정']\n",
                "task_data_dir = preprocessed_dir/'preprocessed_task'\n",
                "task_data_dir.mkdir(exist_ok=True)\n",
                "for task in tasks:\n",
                "    task_path = task_data_dir/task\n",
                "    task_path.mkdir(exist_ok=True)\n",
                "    \n",
                "#### prepare for task preprocess\n",
                "text_set = set()\n",
                "langs =  ['ko-KR', 'es-ES', 'en-US', 'ru-RU', 'en-GB']\n",
                "nationality_set = set()\n",
                "\n",
                "#### prepare for task preprocess end\n",
                "\n",
                "#### task preprocess\n",
                "for split in splits:\n",
                "    source_data_dir_split = source_data_dir/split\n",
                "    task_files = [(task_data_dir/task/f'{split}.jsonl').open('w', encoding='utf-8') for task in tasks]\n",
                "    for source_data in tqdm(list(source_data_dir_split.iterdir()), desc=split):\n",
                "        source_data = source_data.open()\n",
                "        for line in source_data.readlines():\n",
                "            line = json.loads(line)\n",
                "            \n",
                "            #### data preprocess\n",
                "            source_language = line['S-Code']    ## all ko-KR\n",
                "            source_text = line['원문'].replace('  ', ' ').strip()\n",
                "            if edited_source_text:=line['수정원문'] != 'N/A':\n",
                "                source_text = edited_source_text.replace('  ', ' ').strip()\n",
                "            \n",
                "            if source_text in text_set:\n",
                "                continue\n",
                "            text_set.add(source_text)\n",
                "            \n",
                "            target_language = line['T-Code']\n",
                "            preference_order = ['MT', '1차수정', '2차수정', '최종번역문', '수정번역문']\n",
                "            target_texts = ['']\n",
                "            for pref in preference_order:\n",
                "                text = str(line[pref]).replace('  ', ' ').strip()\n",
                "                if text != 'N/A' and target_texts[-1] != text:\n",
                "                    target_texts.append(text)\n",
                "            target_texts = list(reversed(target_texts))[:-1]\n",
                "            target_nationality = line['T-Nationality']\n",
                "            #### data preprocess end \n",
                "            \n",
                "            #### LM(한국어)\n",
                "            data = {'text': source_text}\n",
                "            ## preprocess data from line\n",
                "            ## preprocess data from line end\n",
                "            task_files[0].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "            # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### LM(한국어) end\n",
                "            \n",
                "            \n",
                "            if target_language == 'en-US':\n",
                "                #### LM(영어)\n",
                "                data = {'text': target_texts[0]}\n",
                "                ## preprocess data from line\n",
                "                \n",
                "                ## preprocess data from line end\n",
                "                task_files[1].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "                # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "                #### LM(영어) end\n",
                "            \n",
                "            data = {'input': {}, 'output': None}\n",
                "            data['input']['source_text'] = source_text\n",
                "            data['input']['source_language'] = source_language\n",
                "            data['input']['target_language'] = target_language\n",
                "            data['input']['target_natinality'] = target_nationality\n",
                "            data['output'] = target_texts[0]\n",
                "            \n",
                "            #### 번역(한-영)\n",
                "            if target_language in ['en-US', 'en-GB']:\n",
                "                task_files[2].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "                # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 번역(한-영) end\n",
                "            \n",
                "            \n",
                "            #### 번역(한-러)\n",
                "            if target_language == 'ru-RU':\n",
                "                task_files[3].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "                # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 번역(한-러) end\n",
                "            \n",
                "            \n",
                "            #### 번역(한-스)\n",
                "            if target_language == 'es-ES':\n",
                "                task_files[4].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "                # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "            #### 번역(한-스) end\n",
                "            \n",
                "            \n",
                "            if len(target_texts) > 1:\n",
                "                data['output'] = target_texts\n",
                "                #### 다국어 번역 교정\n",
                "                task_files[5].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "                # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "                #### 다국어 번역 교정 end\n",
                "            \n",
                "            \n",
                "            # break\n",
                "    #     break\n",
                "    # break\n",
                "\n",
                "    for path in task_files:\n",
                "        path.close()      \n",
                "        \n",
                "#### task preprocess end      "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "## save text_set\n",
                "with open('text_set.pkl', 'wb') as f:\n",
                "    pickle.dump(text_set, f)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
