{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train:   0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train: 100%|██████████| 1/1 [00:14<00:00, 14.24s/it]\n",
                        "valid: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import json\n",
                "import re\n",
                "from tqdm import tqdm\n",
                "from collections import defaultdict\n",
                "\n",
                "settings = json.loads(Path('../../../settings.json').read_text())",
                "preprocessed_data_path = Path(settings['preprocessed_data_path'])",
                "data_path = Path('.').resolve()",
                "data_name = data_path.name",
                "source_name = data_path.parent.name",
                "preprocessed_dir = preprocessed_data_path/source_name/data_name",

                "source_data_dir = preprocessed_dir/'preprocessed'\n",
                "splits = ['train', 'valid']\n",
                "tasks = ['LM(한국어)']\n",
                "task_data_dir = preprocessed_dir/'preprocessed_task'\n",
                "task_data_dir.mkdir(exist_ok=True)\n",
                "for task in tasks:\n",
                "    task_path = task_data_dir/task\n",
                "    task_path.mkdir(exist_ok=True)\n",
                "    \n",
                "#### prepare for task preprocess\n",
                "def replace_pattern(text):\n",
                "    pattern = r'\\((.*?)\\)\\/\\((.*?)\\)'\n",
                "    replaced_text = re.sub(pattern, r'\\2', text)\n",
                "    return replaced_text\n",
                "\n",
                "key_mapper = {\n",
                "    'hum' : '인문',\n",
                "    'soc' : '사회',\n",
                "    'edu' : '교육',\n",
                "    'eng' : '공학',\n",
                "    'art' : '예체능',\n",
                "    'gen' : '교양',\n",
                "    'lang' : '언어문학',\n",
                "    'huma' : '인문과학',\n",
                "    'econ' : '경영경제',\n",
                "    'soci' : '사회과학',\n",
                "    'midd' : '중등교육',\n",
                "    'chil' : '유아교육',\n",
                "    'spec' : '특수교육',\n",
                "    'comp' : '컴퓨터통신',\n",
                "    'arch' : '건축',\n",
                "    'elec' : '전기전자',\n",
                "    'desi' : '디자인',\n",
                "    'pysi' : '무용체육',\n",
                "    'basi' : '기초',\n",
                "    'adva' : '학구'\n",
                "}\n",
                "#### prepare for task preprocess end\n",
                "\n",
                "#### task preprocess\n",
                "for split in splits:\n",
                "    text_dict = defaultdict(dict)\n",
                "    source_data_dir_split = source_data_dir/split\n",
                "    task_files = [(task_data_dir/task/f'{split}.jsonl').open('w', encoding='utf-8') for task in tasks]\n",
                "    for source_data in tqdm(list(source_data_dir_split.iterdir()), desc=split):\n",
                "        source_data = source_data.open()\n",
                "        for line in source_data.readlines():\n",
                "            line = json.loads(line)\n",
                "            \n",
                "            #### data preprocess\n",
                "            category = key_mapper[line['01_dataset']['5_category']]\n",
                "            sub_category = key_mapper[line['03_lectureinfo']['3_major_category']]\n",
                "            lecture_id = line['02_srcinfo']['1_id']\n",
                "            transcript_id = line['01_dataset']['3_src_path'].split('/')[-1].split('.')[0]\n",
                "            transcript = replace_pattern(line['06_transcription']['1_text'])\n",
                "            text_dict[lecture_id]['domain'] = [category, sub_category]\n",
                "            if 'transcript' not in text_dict[lecture_id]:\n",
                "                text_dict[lecture_id]['transcript'] = {}\n",
                "            text_dict[lecture_id]['transcript'][transcript_id] = transcript\n",
                "            #### data preprocess end \n",
                "\n",
                "    for key, value in text_dict.items():\n",
                "        #### LM(한국어)\n",
                "        data = {'text': None}\n",
                "        ## preprocess data from line\n",
                "        text = '## domain : ' + ' '.join(value['domain']) + '\\n'\n",
                "        transcript = '\\n'.join([v for k,v in sorted(value['transcript'].items())])\n",
                "        \n",
                "        data['text'] = transcript\n",
                "        ## preprocess data from line end\n",
                "        task_files[0].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "        # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "        #### LM(한국어) end\n",
                "        # break\n",
                "\n",
                "    for path in task_files:\n",
                "        path.close()      \n",
                "        \n",
                "#### task preprocess end      "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
