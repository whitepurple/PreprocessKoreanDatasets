{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train: 100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n",
                        "train: 100%|██████████| 3395/3395 [00:05<00:00, 648.17it/s] \n",
                        "valid: 100%|██████████| 16/16 [00:01<00:00, 15.34it/s]\n",
                        "valid: 100%|██████████| 3387/3387 [00:00<00:00, 15895.25it/s]\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import json\n",
                "import re\n",
                "from tqdm import tqdm\n",
                "\n",
                "settings = json.loads(Path('../../../settings.json').read_text())",
                "preprocessed_data_path = Path(settings['preprocessed_data_path'])",
                "data_path = Path('.').resolve()",
                "data_name = data_path.name",
                "source_name = data_path.parent.name",
                "preprocessed_dir = preprocessed_data_path/source_name/data_name",

                "source_data_dir = preprocessed_dir/'preprocessed'\n",
                "splits = ['train', 'valid']\n",
                "tasks = ['번역(다국어-다국어)']\n",
                "task_data_dir = preprocessed_dir/'preprocessed_task'\n",
                "task_data_dir.mkdir(exist_ok=True)\n",
                "for task in tasks:\n",
                "    task_path = task_data_dir/task\n",
                "    task_path.mkdir(exist_ok=True)\n",
                "    \n",
                "#### prepare for task preprocess\n",
                "\n",
                "from collections import defaultdict\n",
                "\n",
                "def find_consecutive_ranges(input_data):\n",
                "    ranges = defaultdict(list)\n",
                "    n = len(input_data)\n",
                "    \n",
                "    for start in range(n):\n",
                "        current_intersection = input_data[start]\n",
                "        for end in range(start + 1, n + 1):\n",
                "            if end > start + 1:\n",
                "                current_intersection &= input_data[end - 1]\n",
                "            \n",
                "            if len(current_intersection) > 1:\n",
                "                sorted_items = tuple(sorted(current_intersection))\n",
                "                if not ranges[sorted_items] or ranges[sorted_items][-1][1] < start:\n",
                "                    ranges[sorted_items].append((start, end))\n",
                "                else:\n",
                "                    ranges[sorted_items][-1] = (ranges[sorted_items][-1][0], end)\n",
                "            \n",
                "            # If the intersection is empty, no need to check further\n",
                "            if not current_intersection:\n",
                "                break\n",
                "\n",
                "    return ranges\n",
                "#### prepare for task preprocess end\n",
                "\n",
                "#### task preprocess\n",
                "for split in splits:\n",
                "    utt_dict = dict()\n",
                "    source_data_dir_split = source_data_dir/split\n",
                "    task_files = [(task_data_dir/task/f'{split}.jsonl').open('w', encoding='utf-8') for task in tasks]\n",
                "    for source_data in tqdm(list(source_data_dir_split.iterdir()), desc=split):\n",
                "        source_data = source_data.open()\n",
                "        #### data preprocess\n",
                "        for line in source_data.readlines():\n",
                "            line = json.loads(line)\n",
                "            script_id = line['typeInfo']['script']['scriptFileName']\n",
                "            text_id = line['dialogs']['textNumber']\n",
                "            language = line['typeInfo']['language']\n",
                "            utt = {language: line['dialogs']['text']}\n",
                "            if script_id not in utt_dict:\n",
                "                utt_dict[script_id] = {text_id: utt}\n",
                "            else:\n",
                "                if text_id in utt_dict[script_id]:\n",
                "                    utt_dict[script_id][text_id].update(utt)\n",
                "                else:\n",
                "                    utt_dict[script_id][text_id] = utt\n",
                "        #### data preprocess end     \n",
                "            \n",
                "    for key, lang_data in tqdm(utt_dict.items(), desc=split):\n",
                "        lang_data = sorted(lang_data.items())\n",
                "        lang_key_data = [set(v[1].keys()) for v in lang_data]\n",
                "        output = find_consecutive_ranges(lang_key_data)\n",
                "        for items, spans in output.items():\n",
                "            for span in spans:\n",
                "                span_data = lang_data[span[0]:span[1]]\n",
                "                \n",
                "                #### 번역(다국어-다국어)\n",
                "                data = {'en': None, 'ko': None,\n",
                "                        'jp': None, 'es' : None}\n",
                "                for item in items:\n",
                "                    data[item] = ' '.join([d[1][item] for d in span_data])\n",
                "                task_files[0].write(json.dumps(data, ensure_ascii=False)+'\\n')\n",
                "                # print(json.dumps(data, indent=4, ensure_ascii=False))\n",
                "                #### 번역(다국어-다국어) end\n",
                "\n",
                "    for path in task_files:\n",
                "        path.close()      \n",
                "        \n",
                "#### task preprocess end      "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
